{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt_path = r'../data/Create-Face-Data-from-Images-master/model_data/deploy.prototxt'\n",
    "caffemodel_path = r'../data/Create-Face-Data-from-Images-master/model_data/weights.caffemodel'\n",
    "base_dir = r'../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory 'updated_images' if it does not exist\n",
    "raw_path = os.path.join(base_dir, r'data/raw1')\n",
    "if not os.path.exists(raw_path):\n",
    "    print(\"New directory created\")\n",
    "    os.makedirs(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory 'faces' if it does not exist\n",
    "faces_path = os.path.join(base_dir, r'data/faces')\n",
    "if not os.path.exists(faces_path):\n",
    "    print(\"New directory created\")\n",
    "    os.makedirs(faces_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory 'bbox' if it does not exist\n",
    "bbox_path = os.path.join(base_dir, r'data/bbox')\n",
    "if not os.path.exists(bbox_path):\n",
    "    print(\"New directory created\")\n",
    "    os.makedirs(bbox_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.Element(\"annotation\")\n",
    "ET.SubElement(root, \"folder\").text = \"raw\"\n",
    "source = ET.SubElement(root, \"source\")\n",
    "ET.SubElement(source, \"field1\", name=\"blah\", pro='prop1').text = \"C:/\"\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(os.path.join(bbox_path, \"test.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = ET.Element(\"annotation\")\n",
    "# folder = ET.SubElement(root, \"folder\")\n",
    "# folder.text = \"raw\"\n",
    "# source = ET.SubElement(root, \"source\")\n",
    "# ET.SubElement(source, \"field1\", name=\"blah\", pro='prop1').text = \"C:/\"\n",
    "# tree = ET.ElementTree(root)\n",
    "# tree.write(os.path.join(bbox_path, \"test.xml\"))\n",
    "\n",
    "def create_bbox_annotation(image_dict, detections):\n",
    "#     image_dict:\n",
    "#         filename - string, with extension\n",
    "#         width - int\n",
    "#         height - int\n",
    "#         depth - int\n",
    "    \n",
    "    \n",
    "    folder_t = 'raw'\n",
    "    filename_t = image_dict['filename']\n",
    "    path_t = r\"D:\\Documents\\Study\\jupyter_notebook\\haircut\\data\\raw\"\n",
    "    database_t = \"Unknown\"\n",
    "    segmented_t = 0\n",
    "    name_t = \"head\"\n",
    "    pose_t = \"unspecified\"\n",
    "    truncate_t = \"1\"\n",
    "    difficult_t = \"0\"\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    ET.SubElement(root, \"folder\").text = folder_t\n",
    "    ET.SubElement(root, \"filename\").text = filename_t\n",
    "    ET.SubElement(root, \"path\").text = path_t\n",
    "    \n",
    "    source = ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = database_t\n",
    "    \n",
    "    ET.SubElement(root, \"segmented\").text = segmented_t\n",
    "    s = ET.SubElement(root, \"size\")\n",
    "    for i in ['width', 'height', 'depth']:\n",
    "        ET.SubElement(s, i).text = str(image_dict[i])\n",
    "    ET.SubElement(root, \"segmented\").text = segmented_t\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.8:\n",
    "            f_height = endY - startY\n",
    "            offsetX = int((endX - startX)/2)\n",
    "    #         frame = image[max(0, startY - int(f_height/(2.3))):(endY + int(f_height/4)), max(0, startX - offsetX):endX + offsetX]\n",
    "            obj = ET.SubElement(root, \"object\")\n",
    "            ET.SubElement(obj, \"name\").text = name_t\n",
    "            ET.SubElement(obj, \"pose\").text = pose_t\n",
    "            ET.SubElement(obj, \"truncated\").text = truncate_t\n",
    "            ET.SubElement(obj, \"difficult\").text = difficult_t\n",
    "            bbox = ET.SubElement(obj, \"bndbox\")\n",
    "            ET.SubElement(bbox, \"xmin\").text = str(max(0, startX - offsetX))\n",
    "            ET.SubElement(bbox, \"ymin\").text = str(max(0, startY - int(f_height/(2.3))))\n",
    "            ET.SubElement(bbox, \"xmax\").text = str(endX + offsetX)\n",
    "            ET.SubElement(bbox, \"ymax\").text = str((endY + int(f_height/4)))\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(os.path.join(bbox_path, image_dict['filename'].split('.')[0] + \".xml\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path: ../data/raw1/01.jpg\n",
      "Image path: ../data/raw1/02.jpg\n",
      "Image path: ../data/raw1/03.jpg\n",
      "Image path: ../data/raw1/04.jpg\n",
      "Image path: ../data/raw1/05.jpg\n",
      "Image path: ../data/raw1/06.jpg\n",
      "Image path: ../data/raw1/07.jpg\n"
     ]
    }
   ],
   "source": [
    "# Loop through all images and save images with marked faces\n",
    "for file in os.listdir(raw_path)[:7]:\n",
    "    file_name, file_extension = os.path.splitext(file)\n",
    "    if (file_extension in ['.png','.jpg']):\n",
    "        print(\"Image path: {}\".format(raw_path + '/' + file))\n",
    "    image = cv2.imread(os.path.join(raw_path, file))\n",
    "    \n",
    "    height = len(image)\n",
    "    width = len(image[0])\n",
    "    channel = len(image[0][0])\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    model.setInput(blob)\n",
    "    detections = model.forward() \n",
    "    \n",
    "    image_dict = {\n",
    "        'filename': file,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'depth': channel\n",
    "    }\n",
    "    create_bbox_annotation(image_dict, detections)\n",
    "    \n",
    "#     # Create frame around face\n",
    "#     for i in range(0, detections.shape[2]):\n",
    "#         box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "#         (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "#         confidence = detections[0, 0, i, 2]\n",
    "#         offsetY = int((endY - startY)/(2.2))\n",
    "#         offsetX = int((endX - startX)/2)\n",
    "#         # If confidence > 0.5, show box around face\n",
    "#         if (confidence > 0.5):\n",
    "#             pass\n",
    "# #             cv2.rectangle(image, (startX, startY), (endX, endY), (255, 255, 255), 2)\n",
    "# #             cv2.rectangle(image, (max(0,startX-offsetX), max(0,startY-offsetY)), (endX+offsetX, endY+offsetY), (255, 255, 255), 2)\n",
    "            \n",
    "# #     cv2.imwrite('updated_images/' + file, image)\n",
    "# #     print(\"Image \" + file + \" converted successfully\")\n",
    "    \n",
    "#     # Identify each face\n",
    "#     count = 0\n",
    "#     for i in range(0, detections.shape[2]):\n",
    "#         box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "#         (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "#         confidence = detections[0, 0, i, 2]\n",
    "#         # If confidence > 0.5, save it as a separate file\n",
    "#         if (confidence > 0.5):\n",
    "#             count += 1\n",
    "#             offsetY = (endY - startY)//2\n",
    "#             offsetX = (endX - startX)//2\n",
    "# #             frame = image[max(0, startY - offsetY):(endY + offsetY), max(0, startX-offsetX):endX+offsetX]\n",
    "# #             frame = image[startY:endY, startX:endX]\n",
    "#             frame = image[max(0, startY - int((endY - startY)//2.3)):(endY + (endY - startY)//4), max(0, startX-offsetX):endX+offsetX]\n",
    "\n",
    "#             cv2.imwrite(os.path.join(faces_path, str(i) + '__' + file), frame)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
